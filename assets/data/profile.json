{
  "profile": {
    "name": "OtÃ¡vio Ribeiro",
    "title": "Liderando a transformaÃ§Ã£o da jornada de Dados & AI na Educbank",
    "location": "Curitiba, ParanÃ¡, Brasil",
    "summary": "Com mais de 10 anos de experiÃªncia em Engenharia de Dados, atuo na construÃ§Ã£o de arquiteturas modernas e escalÃ¡veis em nuvem, com foco em Data Lakes, Data Warehouses e plataformas de Machine Learning. Minha especializaÃ§Ã£o envolve Databricks e seu ecossistema (Delta Lake, Unity Catalog, Delta Live Tables, Feature Store e MLflow), aplicando boas prÃ¡ticas de governanÃ§a, automaÃ§Ã£o e qualidade de dados em ambientes de grande escala.\n\nTenho forte atuaÃ§Ã£o na lideranÃ§a de equipes multidisciplinares e na implementaÃ§Ã£o de estratÃ©gias data-driven, impulsionando a tomada de decisÃ£o baseada em dados.\n\nMinha experiÃªncia inclui:\nâœ” Modelagem de Data Warehouses (Kimball, Star Schema e Snowflake Schema) para eficiÃªncia analÃ­tica.\nâœ” OrquestraÃ§Ã£o e automaÃ§Ã£o de pipelines com Databricks Workflows, Airflow e dbt, garantindo desempenho e escalabilidade.\nâœ” GovernanÃ§a e qualidade de dados com Unity Catalog, Delta Expectations e validaÃ§Ãµes automatizadas.\nâœ” ExperiÃªncia em Google Cloud Platform (GCP) e Azure, integrando serviÃ§os nativos de Big Data e AI.\nâœ” LideranÃ§a tÃ©cnica e gestÃ£o de times, promovendo cultura data-driven e DevOps, alÃ©m de capacitaÃ§Ã£o em engenharia de dados avanÃ§ada.\n\nEstou sempre em busca de desafios onde possa aplicar minha experiÃªncia em Big Data, governanÃ§a e plataformas em nuvem, desenvolvendo soluÃ§Ãµes escalÃ¡veis, performÃ¡ticas e sustentÃ¡veis.\n\nğŸ“© Interessado em trocar ideias sobre inovaÃ§Ã£o em engenharia de dados e Databricks? Vamos conversar!",
    "updated_at": "2026-02-12T06:20:59.690835Z"
  },
  "timeline": [
    {
      "role": "Gerente de Engenharia de Dados",
      "company": "Educbank",
      "period": "Jan 2025 - Presente",
      "location": "SÃ£o Paulo, Brasil (Remoto)",
      "highlights": [
        "LideranÃ§a de time de engenharia responsÃ¡vel pela transformaÃ§Ã£o da jornada de dados",
        "MigraÃ§Ã£o de Data Warehouse tradicional para arquitetura Lakehouse no Databricks",
        "ImplementaÃ§Ã£o de Unity Catalog, Delta Live Tables e Spark Structured Streaming",
        "GovernanÃ§a de dados com foco em LGPD e boas prÃ¡ticas cloud",
        "Engenharia de ML: validaÃ§Ã£o, operacionalizaÃ§Ã£o e deploy de modelos em produÃ§Ã£o"
      ],
      "description": "Como Gerente de Engenharia de Dados na Educbank, lidero um time altamente capacitado de engenheiros responsÃ¡veis por orquestrar e executar toda a transformaÃ§Ã£o da jornada de dados da empresa. Nossa principal missÃ£o Ã© viabilizar uma cultura verdadeiramente data-driven, tornando os dados acessÃ­veis, confiÃ¡veis e prontos para apoiar decisÃµes estratÃ©gicas em todas as Ã¡reas da organizaÃ§Ã£o.\n\nAssumi um papel central na definiÃ§Ã£o e conduÃ§Ã£o da migraÃ§Ã£o arquitetural da empresa â€” saÃ­mos de uma estrutura tradicional baseada em Data Warehouse, onde as anÃ¡lises eram majoritariamente realizadas via Metabase, para uma arquitetura moderna, elÃ¡stica e escalÃ¡vel, totalmente construÃ­da sobre o Databricks. Essa nova fundaÃ§Ã£o nos permitiu elevar o nÃ­vel de governanÃ§a, desempenho e colaboraÃ§Ã£o em torno dos dados.\n\nNo contexto dessa migraÃ§Ã£o, lidero iniciativas envolvendo o uso avanÃ§ado do Unity Catalog, Delta Live Tables para pipelines declarativos e resilientes, alÃ©m de fluxos de dados em tempo real com Spark Structured Streaming. Toda essa infraestrutura foi pensada com foco em escalabilidade, manutenÃ§Ã£o eficiente e governanÃ§a de dados, respeitando princÃ­pios como LGPD e boas prÃ¡ticas de arquitetura em nuvem.\n\nAlÃ©m da camada de engenharia analÃ­tica, tambÃ©m lidero, em parceria com o time de ciÃªncia de dados, a engenharia de Machine Learning na empresa. Tenho responsabilidade direta pela validaÃ§Ã£o, operacionalizaÃ§Ã£o e disponibilizaÃ§Ã£o de modelos de ML em ambientes produtivos, garantindo que estejam integrados aos produtos internos e que gerem valor real para o negÃ³cio.\n\nEsse papel me permite atuar de ponta a ponta na cadeia de dados â€” desde a ingestÃ£o e modelagem atÃ© a entrega de soluÃ§Ãµes inteligentes baseadas em ML. TambÃ©m invisto constantemente na evoluÃ§Ã£o tÃ©cnica e profissional do time, promovendo um ambiente colaborativo, inovador e orientado a resultados.",
      "skills": "Pipeline de dados Â· AgregaÃ§Ã£o de dados Â· Planejamento de projetos Â· ColaboraÃ§Ã£o em vÃ¡rias funÃ§Ãµes Â· Data Team Leadership Â· Controle de qualidade de dados Â· AutomaÃ§Ã£o de processos Â· Azure Databricks Â· GestÃ£o de equipe tÃ©cnica Â· GestÃ£o de custos Â· EstratÃ©gias de dados Â· Data-driven Â· OtimizaÃ§Ã£o de banco de dados Â· GestÃ£o de projetos Â· Docker Â· CI CD Â· GestÃ£o de equipes Â· GestÃ£o de projetos de software Â· Tomada de decisÃµes baseadas em dados Â· TransformaÃ§Ã£o de dados Â· Metodologias Agile",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/educbank.jpg"
    },
    {
      "role": "Especialista em Dados",
      "company": "Oto CRM",
      "period": "Jan 2024 - Jan 2025",
      "location": "Porto Alegre, Brasil (Remoto)",
      "highlights": [
        "OtimizaÃ§Ã£o de performance em Clickhouse, MySQL e PostgreSQL",
        "LideranÃ§a de time de integraÃ§Ã£o de dados",
        "Desenvolvimento de engines Python para ingestÃ£o em Data Lakes",
        "Coleta dinÃ¢mica de dados de mÃºltiplas fontes (bancos, APIs, plataformas)"
      ],
      "description": "Como Especialista em Dados e lÃ­der tÃ©cnico na OtoCRM, minha atuaÃ§Ã£o estÃ¡ focada em otimizar a performance e garantir a disponibilidade das bases de dados, sendo responsÃ¡vel pela reduÃ§Ã£o de quedas ao colaborar diretamente com o time de backend. Implementamos melhorias significativas nas consultas em Clickhouse, MySQL e PostgreSQL, que resultaram em uma maior eficiÃªncia e estabilidade no sistema.\n\nAlÃ©m disso, lidero um time dedicado Ã  integraÃ§Ã£o de dados, onde desenvolvemos \"engines\" robustas em Python para ingestÃ£o de dados em Data Lakes. Nosso time realiza coletas dinÃ¢micas a partir de diversas fontes â€” sejam bancos de dados, APIs ou outras plataformas fornecidas pelos clientes. Esses processos garantem um fluxo consistente e confiÃ¡vel de dados, essenciais para atender Ã s demandas analÃ­ticas e operacionais da empresa e de nossos clientes.",
      "skills": "GovernanÃ§a de dados Â· IntegraÃ§Ã£o e entrega contÃ­nuas (CI/CD) Â· GitLab Â· Pipeline de dados Â· AgregaÃ§Ã£o de dados Â· Planejamento de projetos Â· Microsoft SQL Server Â· ColaboraÃ§Ã£o em vÃ¡rias funÃ§Ãµes Â· AWS Â· Python Â· Controle de qualidade de dados Â· Data lakes Â· GestÃ£o de tecnologias Â· Modelagem de dados Â· AutomaÃ§Ã£o de processos Â· Azure Databricks Â· Google Cloud Platform (GCP) Â· EstratÃ©gias de dados Â· IntegraÃ§Ã£o de dados do cliente Â· Data-driven Â· OtimizaÃ§Ã£o de banco de dados Â· Arquitetura de dados Â· LideranÃ§a em projetos tÃ©cnicos Â· Docker Â· CI CD Â· GestÃ£o de projetos de software Â· PostgreSQL Â· PHP Â· ClickHouse Â· Apache Airflow Â· Tomada de decisÃµes baseadas em dados Â· TransformaÃ§Ã£o de dados Â· Metodologias Agile",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/otocrm.jpg"
    },
    {
      "role": "LÃ­der TÃ©cnico",
      "company": "DEEP ESG",
      "period": "Ago 2023 - Out 2024",
      "location": "SÃ£o JosÃ© dos Campos, Brasil (Remoto)",
      "highlights": [
        "LideranÃ§a de equipe multidisciplinar (engenheiros de dados + backend)",
        "Modelagem de Data Warehouse com Star Schema (Kimball)",
        "Arquitetura de calculadoras de emissÃ£o de COâ‚‚ e KPIs ESG",
        "Stack: Airflow, DataProc, Cloud Functions (GCP), PostgreSQL, BigQuery"
      ],
      "description": "Como Tech Lead, liderei uma equipe multidisciplinar de engenheiros de dados e desenvolvedores back-end na construÃ§Ã£o de uma arquitetura de dados robusta e escalÃ¡vel, modelada por mim. Supervisionei todo o processo, desde a integraÃ§Ã£o de dados atÃ© a disponibilizaÃ§Ã£o via APIs, garantindo eficiÃªncia e qualidade nas entregas. Implementamos melhorias significativas no controle e utilizaÃ§Ã£o dos bancos de dados PostgreSQL e BigQuery, promovendo uma colaboraÃ§Ã£o mais estreita entre o back-end e a equipe de DBA.\n\nAlÃ©m da lideranÃ§a de equipe, modelei um Data Warehouse utilizando o modelo Star Schema e aplicando os conceitos de modelagem de dados de Kimball, o que otimizou o fluxo de informaÃ§Ãµes e aprimorou as capacidades analÃ­ticas da empresa. TambÃ©m desenvolvi a arquitetura do fluxo de execuÃ§Ã£o das calculadoras de emissÃ£o de COâ‚‚ e outros KPIs ESG, empregando tecnologias como Airflow, DataProc e Cloud Functions no ambiente da Google Cloud Platform (GCP).\n\nMinhas iniciativas resultaram em uma infraestrutura de dados mais eficiente e alinhada Ã s necessidades estratÃ©gicas da empresa, facilitando a tomada de decisÃµes baseada em dados e contribuindo para os objetivos de sustentabilidade corporativa.",
      "skills": "Pipeline de dados Â· AgregaÃ§Ã£o de dados Â· Planejamento de projetos Â· Google Cloud Dataflow Â· ColaboraÃ§Ã£o em vÃ¡rias funÃ§Ãµes Â· Apache Spark Â· Python Â· Data Team Leadership Â· Controle de qualidade de dados Â· Data warehouse Â· Data lakes Â· GestÃ£o de tecnologias Â· Modelagem de dados Â· AutomaÃ§Ã£o de processos Â· GestÃ£o de equipe tÃ©cnica Â· Google Cloud Platform (GCP) Â· EstratÃ©gias de dados Â· Data-driven Â· OtimizaÃ§Ã£o de banco de dados Â· Arquitetura de dados Â· Data Quality Â· CI CD Â· GestÃ£o de projetos de software Â· PostgreSQL Â· Apache Airflow Â· Tomada de decisÃµes baseadas em dados Â· TransformaÃ§Ã£o de dados Â· Metodologias Agile",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/deepesg.jpg"
    },
    {
      "role": "LÃ­der TÃ©cnico",
      "company": "HeroSpark",
      "period": "Dez 2021 - Jul 2023",
      "location": "Curitiba, Brasil",
      "highlights": [
        "CriaÃ§Ã£o e lideranÃ§a de equipe de dados do zero",
        "ImplementaÃ§Ã£o de Data Lake e Data Warehouse",
        "Pipeline de dados com validaÃ§Ã£o e controle de qualidade",
        "PromoÃ§Ã£o de cultura data-driven e capacitaÃ§Ã£o de analistas",
        "Stack: AWS, Metabase, PostgreSQL, Airflow"
      ],
      "description": "Obtive grandes sucessos na criaÃ§Ã£o e lideranÃ§a de uma equipe de dados, alÃ©m de promover uma cultura data-driven. Uma das conquistas mais significativas foi a criaÃ§Ã£o de um Data Lake e um Data Warehouse, que permitiram o armazenamento e a organizaÃ§Ã£o eficiente dos dados da empresa.\n\nCom o estabelecimento do Data Lake, conseguimos centralizar diversas fontes de dados em um Ãºnico local, facilitando o acesso e a anÃ¡lise por parte da equipe. Isso possibilitou uma visÃ£o mais abrangente e integrada dos dados, impulsionando a tomada de decisÃµes estratÃ©gicas baseadas em informaÃ§Ãµes confiÃ¡veis e atualizadas.\n\nAlÃ©m disso, desenvolvemos um fluxo de dados com um pipeline de validaÃ§Ã£o, garantindo a qualidade dos dados que entravam no sistema. AtravÃ©s desse processo, implementamos verificaÃ§Ãµes e filtros para identificar inconsistÃªncias, erros e duplicidades, garantindo que apenas dados confiÃ¡veis e de alta qualidade fossem integrados ao Data Warehouse.\n\nEm paralelo, dediquei-me a promover o conhecimento em SQL e anÃ¡lise baseada em dados entre os analistas juniores. Realizei treinamentos e workshops para capacitÃ¡-los a extrair insights relevantes dos dados, utilizando consultas SQL avanÃ§adas e tÃ©cnicas de anÃ¡lise baseadas no histÃ³rico de dados.",
      "skills": "GovernanÃ§a de dados Â· IntegraÃ§Ã£o e entrega contÃ­nuas (CI/CD) Â· Pipeline de dados Â· AgregaÃ§Ã£o de dados Â· Amazon Web Services Â· Planejamento de projetos Â· Metabase Â· LideranÃ§a de equipe Â· LideranÃ§a Â· MigraÃ§Ã£o de dados Â· Git Â· AnÃ¡lise de dados Â· ColaboraÃ§Ã£o em vÃ¡rias funÃ§Ãµes Â· CoordenaÃ§Ã£o Â· Desenvolvimento de banco de dados Â· Big data Â· Python Â· Data Team Leadership Â· Controle de qualidade de dados Â· EstratÃ©gia empresarial Â· Amazon EC2 Â· Data warehouse Â· Data lakes Â· PL/SQL Â· Linux Â· Modelagem de dados Â· AutomaÃ§Ã£o de processos Â· Banco de dados Â· InteligÃªncia de negÃ³cios (BI) Â· Design de banco de dados Â· Melhoria de processos Â· EstratÃ©gias de dados Â· Shell script Â· LideranÃ§a tÃ©cnica Â· Data-driven Â· OtimizaÃ§Ã£o de banco de dados Â· MongoDB Â· Arquitetura de dados Â· MySQL Â· Aumento de produtividade Â· ComputaÃ§Ã£o em nuvem Â· Data Quality Â· Docker Â· GestÃ£o de desempenho Â· CI CD Â· GestÃ£o de equipes Â· GestÃ£o de projetos de software Â· CiÃªncia de dados Â· PostgreSQL Â· Apache Airflow",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/herospark.jpg"
    },
    {
      "role": "Engenheiro de Dados",
      "company": "Grupo Voalle",
      "period": "Jan 2020 - Out 2020",
      "location": "Santa Maria, Brasil",
      "highlights": [
        "SoluÃ§Ãµes de manutenÃ§Ã£o em massa e migraÃ§Ã£o de dados",
        "MigraÃ§Ã£o MariaDB â†’ PostgreSQL",
        "AutomaÃ§Ã£o com Shell Script e Python",
        "AnÃ¡lise de processos empresariais para aplicaÃ§Ã£o no ERP"
      ],
      "description": "Atuei como Analista de Desenvolvimento, focado em soluÃ§Ãµes de manutenÃ§Ã£o em massa de dados, projetos de migraÃ§Ã£o e automaÃ§Ã£o de processos. Realizei anÃ¡lise e desenvolvimento de soluÃ§Ãµes, mapeamento de legados e planejamento de migraÃ§Ã£o de dados. Desenvolvi rotinas e gatilhos para automaÃ§Ã£o do SGBD e conduzi um projeto de migraÃ§Ã£o do MariaDB para PostgreSQL. Criei scripts em Shell Script e Python para automatizar o tratamento de dados durante as migraÃ§Ãµes. Realizei a manutenÃ§Ã£o dos dados, analisei processos empresariais para aplicaÃ§Ã£o dos dados no ERP e analisei dados em bancos RADIUS. Ofereci suporte aos analistas de atendimento ao cliente e controlei os scripts com o GitLab.",
      "skills": "GovernanÃ§a de dados Â· Pipeline de dados Â· AgregaÃ§Ã£o de dados Â· Transact-SQL Â· MigraÃ§Ã£o de dados Â· Git Â· AnÃ¡lise de dados Â· Microsoft SQL Server Â· Desenvolvimento de banco de dados Â· Big data Â· Python Â· Microsoft Power BI Â· Controle de qualidade de dados Â· EstratÃ©gia empresarial Â· Data warehouse Â· Data lakes Â· PL/SQL Â· Linux Â· Modelagem de dados Â· Banco de dados Â· tratamento de dados Â· Design de banco de dados Â· Melhoria de processos Â· Shell script Â· OtimizaÃ§Ã£o de banco de dados Â· Arquitetura de dados Â· MySQL Â· Aumento de produtividade Â· ComputaÃ§Ã£o em nuvem Â· Data Quality Â· GestÃ£o de desempenho Â· PostgreSQL",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/grupovoalle.jpg"
    },
    {
      "role": "Founder",
      "company": "AdvanceWEB",
      "period": "Jun 2016 - Jan 2020",
      "location": "Ãguas de ChapecÃ³, Brasil",
      "highlights": [
        "FundaÃ§Ã£o e gestÃ£o de startup de software",
        "Desenvolvimento de ImovPedidos (CRM para gestÃ£o de pedidos)",
        "Desenvolvimento de QTMov - Eventos (gestÃ£o de eventos internos)",
        "AdministraÃ§Ã£o, planejamento estratÃ©gico e comercial"
      ],
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/advanceweb.svg"
    },
    {
      "role": "Supervisor de suporte ao cliente",
      "company": "Go Up Software (Viasoft)",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/viasoft.svg",
      "period": "Out 2015 - Mar 2016",
      "location": "Ãguas de ChapecÃ³, Brasil",
      "description": "Trabalhei na franquia GO UP Software, implantando o produto ConstruShow da Viasoft. Realizei anÃ¡lise de processos, aplicando automaÃ§Ã£o na migraÃ§Ã£o de dados com scripts em shell e relatÃ³rios usando JasperSoft. Coordenei a equipe por setor nas implantaÃ§Ãµes in loco em lojas de materiais de construÃ§Ã£o. Adquiri habilidades analÃ­ticas, conhecimento do produto e desenvolvi soluÃ§Ãµes personalizadas para os clientes. A experiÃªncia dinÃ¢mica e os desafios diÃ¡rios me proporcionaram aprendizado constante e a oportunidade de melhorar os processos de negÃ³cio dos clientes. Foi gratificante ver o impacto positivo das soluÃ§Ãµes tecnolÃ³gicas e me motivou a continuar crescendo profissionalmente.",
      "skills": "GovernanÃ§a de dados Â· AgregaÃ§Ã£o de dados Â· LideranÃ§a de equipe Â· LideranÃ§a Â· MigraÃ§Ã£o de dados Â· Git Â· AnÃ¡lise de dados Â· CoordenaÃ§Ã£o Â· Desenvolvimento de banco de dados Â· Big data Â· PL/SQL Â· Linux Â· Banco de dados Â· Banco de dados Oracle Â· tratamento de dados Â· Melhoria de processos Â· ERP (Planejamento de recursos empresariais) Â· Shell script Â· OtimizaÃ§Ã£o de banco de dados Â· MySQL Â· Aumento de produtividade Â· GestÃ£o de desempenho Â· GestÃ£o de equipes Â· ConduÃ§Ã£o de reuniÃµes Â· ETL (ExtraÃ§Ã£o, transformaÃ§Ã£o e carregamento) Â· Tomada de decisÃµes baseadas em dados Â· RecuperaÃ§Ã£o de desastres",
      "highlights": [
        "ImplantaÃ§Ã£o do produto ConstruShow da Viasoft",
        "AutomaÃ§Ã£o de migraÃ§Ã£o de dados com Shell Script",
        "CoordenaÃ§Ã£o de equipe nas implantaÃ§Ãµes in loco",
        "Desenvolvimento de soluÃ§Ãµes personalizadas para clientes"
      ]
    },
    {
      "role": "Gerente de tecnologia da informaÃ§Ã£o",
      "company": "Grupo Rigon",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/rigon.svg",
      "period": "Ago 2013 - Out 2015",
      "location": "Frederico Westphalen, Brasil",
      "description": "Tive a oportunidade de criar um departamento de TI do zero, com foco inicial em projetos de infraestrutura para todas as empresas do grupo. Esses projetos abrangeram desde a implementaÃ§Ã£o de redes de internet e intranet atÃ© a garantia da seguranÃ§a com cÃ¢meras de monitoramento Intelbras, alarmes e controle de entradas e saÃ­das.\n\nPosteriormente, iniciamos anÃ¡lises detalhadas para a contrataÃ§Ã£o de um software ERP especÃ­fico para o ramo do agronegÃ³cio, que era a Ã¡rea principal de atuaÃ§Ã£o do grupo de empresas. Realizamos uma avaliaÃ§Ã£o minuciosa em cada setor, incluindo finanÃ§as, administraÃ§Ã£o, contabilidade, entre outros, com o objetivo de encontrar o melhor produto disponÃ­vel no mercado. ApÃ³s cuidadosa anÃ¡lise, fechamos negÃ³cio com a VIASOFT, adquirindo o produto \"AgroTitan\". Nesse processo, desempenhei um papel fundamental na implantaÃ§Ã£o para garantir o melhor desempenho possÃ­vel.\n\nCom o tempo, Ã  medida que o nÃºmero de colaboradores e terminais aumentava, desenvolvi uma estrutura em Linux Oracle, separando os servidores de banco de dados do servidor de aplicaÃ§Ã£o. Essa arquitetura resultou em um desempenho aprimorado e uma reduÃ§Ã£o na lentidÃ£o do acesso aos dados na intranet.",
      "skills": "GovernanÃ§a de dados Â· AgregaÃ§Ã£o de dados Â· LideranÃ§a de equipe Â· LideranÃ§a Â· AnÃ¡lise de dados Â· CoordenaÃ§Ã£o Â· Desenvolvimento de banco de dados Â· Data Team Leadership Â· EstratÃ©gia empresarial Â· PL/SQL Â· Linux Â· Banco de dados Â· AnÃ¡lise de negÃ³cios Â· Banco de dados Oracle Â· tratamento de dados Â· Design de banco de dados Â· ERP (Planejamento de recursos empresariais) Â· Shell script Â· OtimizaÃ§Ã£o de banco de dados Â· MySQL Â· Aumento de produtividade Â· GestÃ£o de desempenho Â· GestÃ£o de equipes Â· ConduÃ§Ã£o de reuniÃµes Â· ETL (ExtraÃ§Ã£o, transformaÃ§Ã£o e carregamento) Â· Tomada de decisÃµes baseadas em dados Â· RecuperaÃ§Ã£o de desastres",
      "highlights": [
        "CriaÃ§Ã£o do departamento de TI do zero",
        "Projetos de infraestrutura completa (redes, seguranÃ§a, monitoramento)",
        "SeleÃ§Ã£o e implantaÃ§Ã£o de ERP AgroTitan (Viasoft)",
        "Arquitetura Linux Oracle com separaÃ§Ã£o de servidores"
      ]
    },
    {
      "role": "Assistente de TI",
      "company": "Rede Vivo",
      "companyLogo": "/cv-site-otavio/assets/img/profiles/companies/vivo.svg",
      "period": "Fev 2013 - Jun 2013",
      "location": "Santa Maria, Brasil",
      "description": "Ajudar a controlar e instalar perifÃ©ricos de infraestrutura. AÃ§Ãµes como: InstalaÃ§Ã£o e manutenÃ§Ã£o de hardware (servidores Unix); InstalaÃ§Ã£o e manutenÃ§Ã£o de equipamentos de monitoramentos (cÃ¢meras de seguranÃ§a e afins); InstalaÃ§Ã£o e manutenÃ§Ã£o de alarmes; InstalaÃ§Ã£o de telefonia VOIP.",
      "skills": "Linux Â· Shell script Â· MySQL",
      "highlights": [
        "InstalaÃ§Ã£o e manutenÃ§Ã£o de servidores Unix",
        "Equipamentos de monitoramento e seguranÃ§a",
        "InstalaÃ§Ã£o de telefonia VOIP",
        "Controle de infraestrutura de TI"
      ]
    }
  ],
  "projects": [
    {
      "name": "saul_goodman",
      "description": "ExtensÃ£o MV3 para Chrome/Chromium que assume o alter ego vendedor de Saul Goodman para monitorar quanto tempo vocÃª passa em sites produtivos versus procrastinatÃ³rios.",
      "language": "HTML",
      "stars": 2,
      "url": "https://github.com/Donotavio/saul_goodman"
    },
    {
      "name": "cv-site-otavio",
      "description": "Portfolio profissional com Jekyll - OtÃ¡vio Henrique da Silva Ribeiro",
      "language": "HTML",
      "stars": 1,
      "url": "https://github.com/Donotavio/cv-site-otavio"
    },
    {
      "name": "Avaliador-de-Prompt-IA",
      "description": "",
      "language": "Python",
      "stars": 1,
      "url": "https://github.com/Donotavio/Avaliador-de-Prompt-IA"
    },
    {
      "name": "Sentinel",
      "description": "",
      "language": "Swift",
      "stars": 1,
      "url": "https://github.com/Donotavio/Sentinel"
    },
    {
      "name": "Donotavio",
      "description": "",
      "language": "",
      "stars": 0,
      "url": "https://github.com/Donotavio/Donotavio"
    },
    {
      "name": "DON-Auto-Clicker",
      "description": "This repository contains a simple auto clicker software written in Assembly, which can be compiled for Linux, macOS, and Windows. The program allows users to set the execution duration and click rate per minute, making it useful for automating repetitive tasks.",
      "language": "Assembly",
      "stars": 0,
      "url": "https://github.com/Donotavio/DON-Auto-Clicker"
    }
  ],
  "recommendations": [
    {
      "id": "rafael_carvalho",
      "author": "Rafael Carvalho",
      "role": "Director at QuestEdu",
      "company": "QuestEdu",
      "linkedin": "https://www.linkedin.com/in/rafaelmcarvalho/",
      "photo": "/assets/img/profiles/people/rafael-carvalho.jpg"
    },
    {
      "id": "allan_ribeiro",
      "author": "Allan Ribeiro",
      "role": "Front End Software Engineer",
      "company": "HeroSpark",
      "linkedin": "https://www.linkedin.com/in/allanggribeiro/",
      "photo": "/assets/img/profiles/people/allan-ribeiro.jpg"
    },
    {
      "id": "lucas_brandao",
      "author": "Lucas BrandÃ£o",
      "role": "Data Analyst | Data Engineer",
      "company": "HeroSpark",
      "linkedin": "https://www.linkedin.com/in/lucas-brandao-pro/",
      "photo": "/assets/img/profiles/people/lucas-brandao.jpg"
    },
    {
      "id": "fernando_viegas",
      "author": "Fernando Viegas",
      "role": "Data Engineer",
      "company": "HeroSpark",
      "linkedin": "https://www.linkedin.com/in/fernandoviegas92/",
      "photo": "/assets/img/profiles/people/fernando-viegas.jpg"
    },
    {
      "id": "guilherme_maduro",
      "author": "Guilherme Maduro",
      "role": "Product Manager | BI & Analytics",
      "company": "HeroSpark",
      "linkedin": "https://www.linkedin.com/in/guilhermemaduro/",
      "photo": "/assets/img/profiles/people/guilherme-maduro.jpg"
    },
    {
      "id": "jaquelyne_kelm",
      "author": "Jaquelyne Kelm",
      "role": "Gerente de Customer Success",
      "company": "HeroSpark",
      "linkedin": "https://www.linkedin.com/in/jaquelyne-kelm/",
      "photo": "/assets/img/profiles/people/jaquelyne-kelm.jpg"
    }
  ]
}